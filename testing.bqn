# Just some testing for the == and != tokens.
# They naturally have a linear dependency
# ...though you technically could ignore those cause they always will fail to parse.
# Just make any chain of more than 2 equals a lex failure
# Could do the same for anything !== and beyond.
# Kinda like generating the parse error early
# ...I may do that in the final code for simplicity and perf
# Could also technically delay all of this to the parser but that changes token types.
srcâ†"a!===!b====!====!c"
eâ†'='=src
nâ†'!'=src
# This filters out all of the `!=`s
neâ†e(âŠ¢âˆ§Â«âˆ˜âˆ§âŸœÂ»)n
o1â†e (Â¬Â»ne)âŠ¸âˆ§â†©
# Each stage here filters out the leftmost `==` in a group
# Would be done with a repeat instead of manually (repeat based on the max)
o2â†câ†(+Ã—0âŠ¸â‰ )`âŒ¾âŒ½ e
mâ†âŒˆÂ´c
o3â†câ†©(cÃ—âŠ¢Â¬âˆ˜âˆ¨Â»)m=c
mâ†©âŒˆÂ´c
o4â†câ†©(cÃ—âŠ¢Â¬âˆ˜âˆ¨Â»)m=c
# What is left here is the indivial `=`s
mâ†©âŒˆÂ´c
o5â†câ†©(cÃ—âŠ¢Â¬âˆ˜âˆ¨Â»)m=c
â€¢Show >srcâ€¿((âŠ¢âˆ¨Â»)ne)â€¿o1â€¿o2â€¿o3â€¿o4â€¿o5

srcâ†©"true 27 < if if123 let>nolet;"

# Get all the letters, their first index, and the length of chains
azâ†('_'âŠ¸=âˆ¨('a'âŠ¸â‰¤âˆ§â‰¤âŸœ'z')âˆ¨('A'âŠ¸â‰¤âˆ§â‰¤âŸœ'Z')) src
fazâ†(Â»<âŠ¢)az
lazâ†fazÃ—(+Ã—0âŠ¸â‰ )`âŒ¾âŒ½ az

# Do the same thing to get all of the numbers
numâ†('0'âŠ¸â‰¤âˆ§â‰¤âŸœ'9') src
fnumâ†(Â»<âŠ¢)num
lnumâ†fnumÃ—(+Ã—0âŠ¸â‰ )`âŒ¾âŒ½ num

# Match all of the keywords
kwsâ†"fn"â€¿"let"â€¿"true"â€¿"false"â€¿"if"â€¿"else"â€¿"return"
piâ†{/laz=â‰ ğ•©}Â¨kws
kwiâ†pi/ËœÂ¨ kws {kwâ†ğ•¨â‹„{kwâ‰¡(â‰ kw)â†‘ğ•©â†“src}Â¨ğ•©}Â¨ pi

â€¢Show >kwsâ€¿kwi

# All other symbols are just single characters.
# Note: need to use the special info from above for = and !.
tcâ†"=+-!/*<>;,"
fcâ†tcâˆŠËœsrc

â€¢Show >srcâ€¿fazâ€¿lazâ€¿fnumâ€¿lnumâ€¿fc
# This is all of the pieces needed for a monkey lang tokenizer.
# Probably should also double check for no invalid characters instead of skipping them.